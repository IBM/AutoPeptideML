{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoPeptideML API Python\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "The functionalities of AutoPeptideML Python API is focused in a single class, `AutoPeptideML`. Initialization of the class includes 3 possible arguments:\n",
    "\n",
    "- `verbose`: boolean value. Default: `True`.\n",
    "- `threads`: number of threads to use for multithreading. By default it uses all available CPU cores.\n",
    "- `seed`: seed for pseudo-random number generator for all stochastic processes. Default: `42`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from autopeptideml.autopeptideml import AutoPeptideML\n",
    "\n",
    "apml = AutoPeptideML(\n",
    "    verbose=True,\n",
    "    threads=8,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset preparation\n",
    "\n",
    "There are 3 methods to handle dataset preparation:\n",
    "\n",
    "- `autosearch_negatives`: Searches for negative bioactive peptides\n",
    "    - `df_pos`: `pd.DataFrame` with positive samples\n",
    "    - `positive_tags`: `List[str]` with all bioactivities that may overlap with the positive class\n",
    "    - `proportion`: `float` number. Target negative:positive ratio. Default:  `1.0`.\n",
    "- `balance_samples`: Balances labels in the dataset by oversampling the underepresented classes.\n",
    "    - `df`: `pd.DataFrame`. Dataframe with `Y` column, for which labels will be balanced.\n",
    "- `curate_dataset`: Load the dataset, remove non-canonical and empty sequences.\n",
    "    - `dataset`: `Union[str, pd.DataFrame]`. The input can be either the path to a `.fasta`, `.csv`, or `.tsv` file or a `pd.DataFrame`.\n",
    "    - `outputdir`: `str`. Path to a directory where to save the curated dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset curation\n",
    "df_negs = apml.curate_dataset(\n",
    "    dataset='example_dataset_with_negatives.fasta',\n",
    "    output='output_dir'\n",
    ")\n",
    "df_pos = apml.curate_dataset(\n",
    "    dataset='example_dataset_with_positives.fasta',\n",
    "    output='output_dir_2'\n",
    ")\n",
    "\n",
    "# Balance samples_to_draw (only if df contains negative samples)\n",
    "df_negs_balanced = apml.balance_samples(df_negs)\n",
    "\n",
    "# Autosearch for negatives\n",
    "df = apml.autosearch_negatives(\n",
    "    df_pos=df_pos,\n",
    "    positive_tags=['Neuropeptides'],\n",
    "    proportion=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset partitioning\n",
    "\n",
    "There are two steps of dataset partitioning: training/evaluation and training/validation folds.\n",
    "\n",
    "- `train_test_partition`: Creates training/evaluation sets using novel homology partitioning algorithm\n",
    "    - `df`: `pd.DataFrame`\n",
    "    - `threshold`: `float`. Maximum sequence identity value between sequences in training and evaluation sets. Default: `0.3`\n",
    "    - `test_size`: `float`. Proportion of samples that should comprise the evaluation set. Default: `0.2`\n",
    "    - `alignment`: `str`. Alignment method to be used. Options: `needle`, `mmseqs` and `mmseqs+prefilter`. Default: `mmseqs+prefilter`\n",
    "    - `outputdir`: `str`. Path to a directory where to save the generated datasets.\n",
    "- `train_val_partition`: Creates n training/validation folds\n",
    "    - `df`: `pd.DataFrame`. Should be the training dataset generated with the previous step.\n",
    "    - `method`: `str`. Method for partitioning. Options: `random` and `graph-part`. `random` refers to `StratifiedKFold` from `sklearn.model_selection` and `graph-part` to `stratified_k_fold` from the GraphPart algorithm. For more details see the [Project Github Repository](https://github.com/graph-part/graph-part).\n",
    "    - `threshold`: `float`. Maximum sequence identity value between sequences in training and valdation folds. Only valid if method is `graph-part`. Default: `0.5`.\n",
    "    - `alignment`: `str`. Alignment method to be used. Options: `needle`, `mmseqs` and `mmseqs+prefilter`. Only valid if method is `graph-part`. Default: `mmseqs+prefilter`.\n",
    "    - `n_folds`: `int`. Number of folds to be generated. Default: `10`.\n",
    "    - `outputdir`: `str`. Path to a directory where to save the generated datasets.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "datasets = apml.train_test_partition(\n",
    "    df=df,\n",
    "    threshold=0.3,\n",
    "    test_size=0.2,\n",
    "    alignment='mmseqs+prefilter',\n",
    "    outputdir='outputdir/splits'\n",
    ")\n",
    "folds = apml.train_val_partition(\n",
    "    df=datasets['train'],\n",
    "    method='random',\n",
    "    n_folds=10,\n",
    "    outputdir='outputdir/folds'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Peptide Representation\n",
    "\n",
    "The Peptide Representation step requires an additional class within the AutoPeptideML package, `RepresentationEngine`, that loads the Protein Language Model (PLM) of choice.\n",
    "\n",
    "- `RepresentationEngine`:\n",
    "    - `model`: `str`. Protein Language Model, see Github Repo `README.md` file. Default: `esm2-8m`\n",
    "    - `batch_size`: Number of peptide sequences to compute in each batch, depends on the RAM memory either in the CPU or the GPU. Default: `64`.\n",
    "- `AutoPeptideML`:\n",
    "    - `compute_representation`: Uses the `RepresentationEngine` class to compute the representations in the dataset.\n",
    "        - `datasets`: `Dict[str, pd.DataFrame]` dictionary with the dataset partitions\n",
    "        - `re`: `RepresentationEngine`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from autopeptideml.utils.embeddings import RepresentationEngine\n",
    "\n",
    "re = RepresentationEngine(\n",
    "    model='esm2-8m',\n",
    "    batch_size=64\n",
    ")\n",
    "id2rep = apml.compute_representations(\n",
    "    datasets=datasets,\n",
    "    re=re\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter Optimisation and Model Training\n",
    "\n",
    "- `hpo_train`\n",
    "    - `config`: `dict`. `JSON` file with the hyperparameter search space, for examples of the format please refer to the files in `autopeptideml/data/configs`.\n",
    "    - `train_df`: `pd.DataFrame` with the training dataset.\n",
    "    - `id2rep`: `dict`. Result from running `apml.compute_representation`\n",
    "    - `folds`: `list`. List of training/validation folds.\n",
    "    - `outputdir`: `str`. Path to a directory where to save the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = apml.hpo_train(\n",
    "    config=json.load(open('../autopeptideml/data/config/default_config.json')),\n",
    "    train_df=datasets['train],\n",
    "    id2rep=id2rep,\n",
    "    folds=folds,\n",
    "    outputdir='outputdir/ensemble'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ensemble Evaluation\n",
    "\n",
    "- `evaluate_model`\n",
    "    - `best_model`. Ensemble generated in previous step.\n",
    "    - `test_df`: `pd.DataFrame` with the evaluation set.\n",
    "    - `id2rep`: `dict`. Representations generated in Step 4\n",
    "    - `outputdir`: `str`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "results = apml.evaluate_model(\n",
    "    best_model=model,\n",
    "    test_df=datasets['test'],\n",
    "    id2rep=id2rep,\n",
    "    outputdir='outputdir/results'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prediction\n",
    "\n",
    "- `predict`: Predict the bioactivity of a set of peptide sequences given an ensemble already trained.\n",
    "    - `df`: `pd.DataFrame` with the peptide sequences.\n",
    "    - `re`: `RepresentationEngine`\n",
    "    - `ensemble_path`: Path where the ensemble files were saved.\n",
    "    - `outputdir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "apml.predict(\n",
    "    df=pd.read_csv('New_samples.csv'),\n",
    "    re=re,\n",
    "    ensemble_path='outputdir/ensemble',\n",
    "    outputdir='prediction'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
